{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/milindpatil/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/milindpatil/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages (from gym) (1.21.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/milindpatil/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/milindpatil/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages (from gym) (4.8.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/milindpatil/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/milindpatil/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wvqHkiUxn5zc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gym\n",
    "\n",
    "from gridworld import *\n",
    "# from analyze import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Aemga1sgoMWJ",
    "outputId": "3189cf07-7424-42fd-f106-11dda7d6617a"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridWorld' object has no attribute 'number_of_interestpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tw/vbrqfbx93j5g0qg2s07y9bsh0000gn/T/ipykernel_37350/470985629.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mobservation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridWorld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_robots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_interestpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnumber_of_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Assignment 2/gridworld.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, number_of_robots, number_of_interestpoints, dim, observation_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_robots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_robots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_interestpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_interestpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_robots\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_interestpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridWorld' object has no attribute 'number_of_interestpoints'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #runtime = 100\n",
    "    filename_state = 'state'\n",
    "    filename_qtable = 'qtable'\n",
    "    filename_results = 'results'\n",
    "    number_of_robots = 2\n",
    "    number_of_interestpoints = 2\n",
    "    dimension = 4\n",
    "    observation_size = (3, 84, 84)\n",
    "    env = GridWorld(number_of_robots, number_of_interestpoints, dimension, observation_size)\n",
    "\n",
    "    number_of_episodes = 4000\n",
    "    env.train(number_of_episodes)\n",
    "    # analyze_convergence()\n",
    "    env.visualize_training(filename_state, number_of_episodes)\n",
    "    # env.evaluate(filename_qtable)\n",
    "    # env.visualize(filename_results)\n",
    "    env.close()\n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.suptitle('Plot Steps and Reward Buffer')\n",
    "    axs[0].plot(range(len(rew_buf)), rew_buf)\n",
    "    axs[1].plot(range(len(steps)), steps)\n",
    "    #plt.plot(range(len(rew_buf)),rew_buf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwJOrqkDqI2D"
   },
   "source": [
    "# Final Comments\n",
    "We can conclude from the above plots that the number of rewards keeps rising and essentially stays the same after a few episodes. Inconsistencies exist in the rewards between related episodes. 2. After each episode, the steps required to reach the interest point get progressively shorter, however there may be some variation. 3. The algorithm converges at a faster pace when the learning rate and discount factor are high and low, respectively. This results in fewer steps being needed and higher rewards. While the method takes longer to converge when the learning rate and discount rate are low and high, necessitating more steps and fewer rewards."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
